# Ajuste de modelos

```{r include=FALSE}
knitr::opts_chunk$set(cache=T, warning=FALSE, message=FALSE)
library(arm)
library(ggplot2)
library(tidyr)
library(dplyr)
library(ISLR); data(Hitters)

rss <- function(fitted, actual){
  sum((fitted - actual)^2)
}

rmse <- function(fitted, actual){
  sqrt(mean((fitted - actual)^2))
}

R2 <- function(fitted, actual){
  tss <- sum((actual - mean(actual))^2)
  rss <- sum((actual - fitted)^2)
  1 - rss/tss
}
```

Este capítulo cubre varios temas adicionales relacionados con el ajuste de modelos, como la selección de variables, la comparación de modelos, la validación cruzada y la imputación de datos faltantes. Los conceptos y métodos discutidos aquí se aplican tanto a la regresión lineal como a la logística.


Qué pretendemos aprender en este capítulo:

- Saber cuales son las reglas generales para seleccionar variables en un modelo.
- Aprender a llevar a cabo esta selección con métodos automáticos (stepwise).
- Cómo comparar dos modelos
- Cómo determinar si un modelo tiene sobre-ajuste (overfitting)
- Dar una pequeña idea a qué hacer cuando tenemos datos faltantes (missing data)


## Reglas generales para la selección de variables

¿Cómo sabemos qué variables (independientes) deben incluirse en un modelo? La respuesta sencilla es: a menudo no lo sabemos. Aquí hay algunas reglas generales cuando se piensa en la selección de variables:

- *Piensar en los datos*. ¿Qué variables tiene sentido incluir dada la situación? ¿Alguna literatura publicada ofrece orientación? Si estamos en modo descriptivo, es posible que solo nos interesen determinadas variables y utilicemos las demás como controles. Si estamos en modo predictivo, incluimos todas las variables que, por razones aditivas, podrían ser importantes para predecir el resultado. Sin embargo, esta es una guía muy general, ya que diferentes contextos exigen diferentes enfoques para el ajuste del modelo.

- *Incluir términos cuadráticos si hay evidencia de gráficos bivariados de una relación no lineal entre predictor y resultado.* En general, no incluimos términos polinomiales con grados superiores a 2. Para hacerlo, se corre el riesgo de sobreajuste (término del que hablaremos más tarde).

- *Buscar posibles interacciones entre variables con los efectos principales más grandes.* En general, no incluimos interacciones de orden superior (mayores que 2) a menos que tengamos una razón lógica y podamos explicarla. También hay que tener en cuenta que las interacciones son bastante difíciles de explicar.

- *Considerar combinar predictores separados en un solo predictor --- un "puntaje total" --- obtenido al sumarlos o promediarlos.*

- *Simplicidad.* Los modelos sencillos son casi siempre mejores --- son más interpretables y tienden a tener menor variación (*principio de parsimonia*).
